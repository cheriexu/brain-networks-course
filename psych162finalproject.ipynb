{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "psych162finalproject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "No8upqT7yV2e",
        "mj1dEiZhy1sZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheriexu/brain-networks-course/blob/master/psych162finalproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EdPoQ1FB5ZxN",
        "colab_type": "code",
        "outputId": "39c7c081-c229-4c92-f742-95249d1646f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "#This is how we are going to do our project, colab gives us GPU usage up to 12 hr for free\n",
        "!pip install numpy pandas matplotlib nibabel nilearn scipy sklearn keras"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.7)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "llLIrkL37bIb",
        "colab_type": "code",
        "outputId": "c29b94dd-acda-4069-9bb7-5fa0c3f1294a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F1KH5yZk7WgU",
        "colab_type": "code",
        "outputId": "bc052665-d40d-409e-e37c-0fe33f031290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/'My Drive'/PSYCH162"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PSYCH162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mvNm3pomsDy_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"sampled_pheno.csv\") #We have phenotypical data here too \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XP924be3yQ16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "23d5a009-fa1c-497a-a63f-5d6b72a5be63"
      },
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'SUB_ID', 'X',\n",
              "       'subject', 'SITE_ID', 'FILE_ID', 'DX_GROUP', 'DSM_IV_TR',\n",
              "       ...\n",
              "       'qc_notes_rater_1', 'qc_anat_rater_2', 'qc_anat_notes_rater_2',\n",
              "       'qc_func_rater_2', 'qc_func_notes_rater_2', 'qc_anat_rater_3',\n",
              "       'qc_anat_notes_rater_3', 'qc_func_rater_3', 'qc_func_notes_rater_3',\n",
              "       'SUB_IN_SMP'],\n",
              "      dtype='object', length=107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "No8upqT7yV2e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get data: do not run again"
      ]
    },
    {
      "metadata": {
        "id": "Htw3m7SHwc2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df_small = df[df].sample(200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2Pr4mAKtW7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/cpac/filt_global/alff/'FILEIDHERE'.nii.gz\n",
        "#Example URL\n",
        "#!wget 'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/cpac/func_minimal/Pitt_0050003_func_minimal.nii.gz'\n",
        "#ITERATE THROUGH and then unzip (1112)\n",
        "\n",
        "#DON'T RUN THIS AGAIN, ALREADY COLLECTED\n",
        "\n",
        "'''for file_id in df_small['FILE_ID']:\n",
        "  firstUrl = 'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/cpac/filt_global/rois_ho/'\n",
        "  filename = file_id+'_rois_ho.1D'\n",
        "  !wget \"$firstUrl$filename\"\n",
        "  #!gunzip $filename'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eL3hp3xKnYMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df_small.to_csv('sampled_pheno.csv',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-y2o5ua0yHgX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compute Correlational Matrices for Subjects"
      ]
    },
    {
      "metadata": {
        "id": "m6JcJy8nzmTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "270a65ff-7ae3-4e37-9d4c-b32c563bf0de"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "import os\n",
        "import numpy as np\n",
        "directory = os.fsencode('.')\n",
        "connectome_measure = ConnectivityMeasure(kind = 'correlation')\n",
        "correlations = []\n",
        "corr_org = []\n",
        "files = []\n",
        "for file in os.listdir(directory):\n",
        "  #print(file)\n",
        "  filename = os.fsdecode(file)\n",
        "  if filename.endswith(\".1D\"):\n",
        "    files.append(filename)\n",
        "    df = pd.read_csv(filename,sep='\\t')\n",
        "    corr = connectome_measure.fit_transform([df.as_matrix()])\n",
        "    corr_org.append(corr)\n",
        "    corr = np.reshape(corr,(111,111))\n",
        "    correlations.append(corr)\n",
        "print(len(files))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XskvflXZyvkZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get Phenotypic Dara"
      ]
    },
    {
      "metadata": {
        "id": "ftUUW-mity3L",
        "colab_type": "code",
        "outputId": "80854cc9-b9af-48cd-c1be-e95e4fe21ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"sampled_pheno.csv\") #We have phenotypical data here too \n",
        "file_id = [file[0:file.index('_rois_ho.1D')] for file in files]\n",
        "df = df.loc[df['FILE_ID'].isin(file_id)]\n",
        "print(df.columns)\n",
        "diagnoses_group = [df.loc[df['FILE_ID'] == f]['DX_GROUP'].values[0] for f in file_id]\n",
        "pdd_category = [df.loc[df['FILE_ID'] == f]['DSM_IV_TR'].values[0] for f in file_id]\n",
        "adi_r_social = [df.loc[df['FILE_ID'] == f]['ADI_R_SOCIAL_TOTAL_A'].values[0] for f in file_id]\n",
        "\n",
        "adi_r_verbal= [df.loc[df['FILE_ID'] == f]['ADI_R_VERBAL_TOTAL_BV'].values[0] for f in file_id]\n",
        "ados_total = [df.loc[df['FILE_ID'] == f]['ADOS_TOTAL'].values[0] for f in file_id]\n",
        "ados_serverity = [df.loc[df['FILE_ID'] == f]['ADOS_GOTHAM_SEVERITY'].values[0] for f in file_id]\n",
        "ados_socaffect = [df.loc[df['FILE_ID'] == f]['ADOS_GOTHAM_SOCAFFECT'].values[0] for f in file_id]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'SUB_ID', 'X',\n",
            "       'subject', 'SITE_ID', 'FILE_ID', 'DX_GROUP', 'DSM_IV_TR',\n",
            "       ...\n",
            "       'qc_notes_rater_1', 'qc_anat_rater_2', 'qc_anat_notes_rater_2',\n",
            "       'qc_func_rater_2', 'qc_func_notes_rater_2', 'qc_anat_rater_3',\n",
            "       'qc_anat_notes_rater_3', 'qc_func_rater_3', 'qc_func_notes_rater_3',\n",
            "       'SUB_IN_SMP'],\n",
            "      dtype='object', length=107)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ava-X8OC08O9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*   DX_GROUP Diagnostic Group Numeric 1=Autism; 2=Control 1 2 2 DX_GROUP\n",
        "*   PDD_DSM_IV_TR DSM-IV-TR PDD Category Numeric 0=none; 1=Autism; 2=Aspergers; 3=PDD-NOS 0 3 3 DSM_IV_TR\n",
        "* ASD_DSM_5 DSM-5 ASD Category Numeric 0=none; 1=ASD 0 1 NA \n",
        "* ADI_R_SOCIAL_TOTAL_A Autism Diagnsoitc Interview-Revised Reciprocal Social Interaction Subscore \n",
        "* ADI_R_VERBAL_TOTAL_BV Abnormalities in Communication Subscore Verbal B(V) Total\n",
        "* ADI_R_NONVERBAL_TOTAL_BV Abnormalities in Communication Subscore Nonverbal B(NV) Total \n",
        "* ADI_R_RRB_TOTAL_C Restricted, Repetitive, and Sterestyped Patterns of Behavior (C) Total\n",
        "* ADOS_G_TOTAL ADOS Generic or ADOS-2 Module 4 Total Score\n",
        "* ADOS_2_TOTAL ADOS-2 Total Score\n",
        "* ADOS_2_SOCAFFECT ADOS-2 Social Affect Total \n",
        "* ADOS_2_TOTAL ADOS-2 Total Score\n",
        "* ADOS_2_SEVERITY_TOTAL ADOS-2 Calibrated Severity Total Score \n",
        "\n",
        "http://fcon_1000.projects.nitrc.org/indi/abide/ABIDEII_Data_Legend.pdf\n",
        "\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "MoWNO_pIvPa1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### K means Clustering Code"
      ]
    },
    {
      "metadata": {
        "id": "mj1dEiZhy1sZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dunn indices (defunct)"
      ]
    },
    {
      "metadata": {
        "id": "wA5AQnsEtY9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "\n",
        "def normalize_to_smallest_integers(labels):\n",
        "    \"\"\"Normalizes a list of integers so that each number is reduced to the minimum possible integer, maintaining the order of elements.\n",
        "    :param labels: the list to be normalized\n",
        "    :returns: a numpy.array with the values normalized as the minimum integers between 0 and the maximum possible value.\n",
        "    \"\"\"\n",
        "\n",
        "    max_v = len(set(labels)) if -1 not in labels else len(set(labels)) - 1\n",
        "    sorted_labels = np.sort(np.unique(labels))\n",
        "    unique_labels = range(max_v)\n",
        "    new_c = np.zeros(len(labels), dtype=np.int32)\n",
        "\n",
        "    for i, clust in enumerate(sorted_labels):\n",
        "        new_c[labels == clust] = unique_labels[i]\n",
        "\n",
        "    return new_c\n",
        "\n",
        "\n",
        "def dunn(labels, distances):\n",
        "    \"\"\"\n",
        "    Dunn index for cluster validation (the bigger, the better)\n",
        "    \n",
        "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
        "    \n",
        "    where :math:`d(c_i,c_j)` represents the distance between\n",
        "    clusters :math:`c_i` and :math:`c_j`, given by the distances between its\n",
        "    two closest data points, and :math:`diam(c_k)` is the diameter of cluster\n",
        "    :math:`c_k`, given by the distance between its two farthest data points.\n",
        "    \n",
        "    The bigger the value of the resulting Dunn index, the better the clustering\n",
        "    result is considered, since higher values indicate that clusters are\n",
        "    compact (small :math:`diam(c_k)`) and far apart.\n",
        "    :param labels: a list containing cluster labels for each of the n elements\n",
        "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
        "    \n",
        "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
        "    \"\"\"\n",
        "\n",
        "    labels = normalize_to_smallest_integers(labels)\n",
        "\n",
        "    unique_cluster_distances = np.unique(min_cluster_distances(labels, distances))\n",
        "    max_diameter = max(diameter(labels, distances))\n",
        "\n",
        "    if np.size(unique_cluster_distances) > 1:\n",
        "        return unique_cluster_distances[1] / max_diameter\n",
        "    else:\n",
        "        return unique_cluster_distances[0] / max_diameter\n",
        "\n",
        "\n",
        "def min_cluster_distances(labels, distances):\n",
        "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
        "    :param labels: a list containing cluster labels for each of the n elements\n",
        "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
        "    \"\"\"\n",
        "    labels = normalize_to_smallest_integers(labels)\n",
        "    n_unique_labels = len(np.unique(labels))\n",
        "\n",
        "    min_distances = np.zeros((n_unique_labels, n_unique_labels))\n",
        "    for i in np.arange(0, len(labels) - 1):\n",
        "        for ii in np.arange(i + 1, len(labels)):\n",
        "            if labels[i] != labels[ii] and distances[i, ii] < min_distances[labels[i], labels[ii]]:\n",
        "                min_distances[labels[i], labels[ii]] = min_distances[labels[ii], labels[i]] = distances[i, ii]\n",
        "    return min_distances\n",
        "\n",
        "\n",
        "def diameter(labels, distances):\n",
        "    \"\"\"Calculates cluster diameters (the distance between the two farthest data points in a cluster)\n",
        "    :param labels: a list containing cluster labels for each of the n elements\n",
        "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
        "    :returns:\n",
        "    \"\"\"\n",
        "    labels = normalize_to_smallest_integers(labels)\n",
        "    n_clusters = len(np.unique(labels))\n",
        "    diameters = np.zeros(n_clusters)\n",
        "\n",
        "    for i in np.arange(0, len(labels) - 1):\n",
        "        for ii in np.arange(i + 1, len(labels)):\n",
        "            if labels[i] == labels[ii] and distances[i, ii] > diameters[labels[i]]:\n",
        "                diameters[labels[i]] = distances[i, ii]\n",
        "    return diameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKp_iIa9tab2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Start K means"
      ]
    },
    {
      "metadata": {
        "id": "NRLFjs6vvNl4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt \n",
        "from sklearn import cluster\n",
        "from nilearn import plotting\n",
        "from sklearn import metrics\n",
        "num_cluster = [7]\n",
        "clustering = []\n",
        "for n in num_cluster:\n",
        "  count = 0\n",
        "  \n",
        "  for corr in correlations:\n",
        "    title = 'Original Correlation matrix with '+str(n)\n",
        "    \n",
        "    results = cluster.KMeans(n_clusters=n).fit_predict(corr)\n",
        "    clustering.append(results)\n",
        " \n",
        "    '''if count %20 == 0:\n",
        "      display = plotting.plot_matrix(corr, vmax=1, vmin=-1,\n",
        "                                 colorbar=True, title=title)\n",
        "      tmp = corr[np.argsort(results),:]\n",
        "      clustered = tmp[:,np.argsort(results)]\n",
        "      title2 = 'Clustered Correlation matrix with '+str(n) \n",
        "      display = plotting.plot_matrix(clustered, vmax=1, vmin=-1,\n",
        "                                 colorbar=True, title=title2)'''\n",
        "    count+=1\n",
        "  #silhouette = [metrics.silhouette_score(correlations[i], clustering[i]) for i in range(len(correlations))]\n",
        "  #ch_score = [metrics.calinski_harabaz_score(correlations[i], clustering[i]) for i in range(len(correlations))]\n",
        "  #d=  dunn(clustering[0], euclidean_distances(correlations[0]))\n",
        "  #print(d)\n",
        "  #print(\"Silhouette Coefficient for \",n ,' clusters',np.array(silhouette))\n",
        "  #print(\"Dunn index for \",n ,' clusters',np.mean(np.array(d)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WefywjmpraU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "intra_cluster_corr = []\n",
        "for c in range(len(clustering)):\n",
        "  cluster_corr = []\n",
        "  for idx in range(num_cluster[0]):\n",
        "    corr = correlations[c]\n",
        "    cluster = clustering[c]\n",
        "    corrmatrix = np.corrcoef(corr[np.where(cluster == idx)])\n",
        "    upper = np.triu_indices(corrmatrix.shape[0], 1)\n",
        "    cluster_corr.append(np.mean(corrmatrix[upper]))\n",
        "  intra_cluster_corr.append(cluster_corr)\n",
        "    \n",
        "regressors = np.array(intra_cluster_corr)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJb6PkM96qRy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Regression"
      ]
    },
    {
      "metadata": {
        "id": "AAfxduX3wmmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1e2ba1f5-b26e-42e4-b2df-6a6180f8390c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "logisticRegr = SVC(gamma = 'auto')#LogisticRegression()\n",
        "logisticRegr.fit(regressors, np.array(diagnoses_group))\n",
        "logisticRegr.predict(regressors)\n",
        "score = logisticRegr.score(regressors,np.array( diagnoses_group))\n",
        "print(\"For Diagnoses prediction\", score)\n",
        "\n",
        "lrmt = SVC(gamma = 'auto')#= LogisticRegression(multi_class='multinomial', solver = 'saga')\n",
        "y = np.array(pdd_category)\n",
        "lrmt.fit(regressors,y)\n",
        "lrmt.predict(regressors)\n",
        "score = lrmt.score(regressors,y)\n",
        "print ('PDD Category from DSM IV ', score)\n",
        "\n",
        "lr = LinearRegression()\n",
        "y = np.array(adi_r_social)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = regressors[np.where(~np.isnan(y))]\n",
        "y = y[ np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"adi-r-social \", score)\n",
        "\n",
        "y= np.array(adi_r_verbal)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = regressors[np.where(~np.isnan(y))]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"adi-r-verbal \", score)\n",
        "\n",
        "y= np.array(ados_total)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = regressors[np.where(~np.isnan(y))]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"ados total \", score)\n",
        "\n",
        "y= np.array(ados_serverity)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = regressors[np.where(~np.isnan(y))]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"ados serverity \", score)\n",
        "\n",
        "y= np.array(ados_socaffect)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = regressors[np.where(~np.isnan(y))]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"ados social affect \", score)\n",
        "\n"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Diagnoses prediction 0.5760869565217391\n",
            "PDD Category from DSM IV  0.4891304347826087\n",
            "adi-r-social  0.27180591929103937\n",
            "adi-r-verbal  0.25633060666040164\n",
            "ados total  0.1053232406272614\n",
            "ados serverity  0.1874748108353732\n",
            "ados social affect  0.22375285008442047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tt513FXes8g3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "Classification accuracy:\n",
        "\n",
        "* For Diagnoses prediction 0.5760869565217391\n",
        "* PDD Category from DSM IV  0.4891304347826087\n",
        "\n",
        "Regression Correlation:\n",
        "* adi-r-social  0.27180591929103937\n",
        "* adi-r-verbal  0.25633060666040164\n",
        "* ados total  0.1053232406272614\n",
        "* ados serverity  0.1874748108353732\n",
        "* ados social affect  0.22375285008442047\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m3MAfS2-mXdu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create cross correlation matrix across all time series for each subject \\\\\n",
        "Store data in pandas dataframe \\\\\n",
        "Use kmeans to cluster for baseline \\\\\n",
        "Regress with psychometric data \\\\\n",
        "Question: whether to use ALFF or minimally processed data\\\\\n",
        "VAE and K means loss \n"
      ]
    },
    {
      "metadata": {
        "id": "84Of_TSCA4Ek",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#VAE Clustering"
      ]
    },
    {
      "metadata": {
        "id": "E0DIL9-iJFpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e185eb64-530e-4892-ebe8-c6ce78505101"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras import metrics\n",
        "from keras import backend as K   # 'generic' backend so code works with either tensorflow or theano\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "np.random.seed(237)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
            "  return _inspect.getargspec(target)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4900: ResourceWarning: unclosed file <_io.TextIOWrapper name='/root/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
            "  _config = json.load(open(_config_path))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nFeAwlIql13O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_shape = (111, 111,1)    \n",
        "batch_size = 6\n",
        "latent_dim = 7# Number of latent dimension parameters\n",
        "\n",
        "# Encoder architecture: Input -> Conv2D*4 -> Flatten -> Dense\n",
        "input_img = keras.Input(shape=img_shape)\n",
        "\n",
        "x = layers.Conv2D(32, 3,\n",
        "                  padding='same', \n",
        "                  activation='relu')(input_img)\n",
        "x = layers.Conv2D(64, 3,\n",
        "                  padding='same', \n",
        "                  activation='relu',\n",
        "                  strides=(3, 3))(x)\n",
        "x = layers.Conv2D(64, 3,\n",
        "                  padding='same', \n",
        "                  activation='relu')(x)\n",
        "x = layers.Conv2D(64, 3,\n",
        "                  padding='same', \n",
        "                  activation='relu')(x)\n",
        "# need to know the shape of the network here for the decoder\n",
        "shape_before_flattening = K.int_shape(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# Two outputs, latent mean and (log)variance\n",
        "z_mu = layers.Dense(latent_dim)(x)\n",
        "z_log_sigma = layers.Dense(latent_dim)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kfxEQ06Ml2qS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sampling function\n",
        "def sampling(args):\n",
        "    z_mu, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mu)[0], latent_dim),\n",
        "                              mean=0., stddev=1.)\n",
        "    return z_mu + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "# sample vector from the latent distribution\n",
        "z = layers.Lambda(sampling)([z_mu, z_log_sigma])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z2nUZyCAl2-n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# decoder takes the latent distribution sample as input\n",
        "decoder_input = layers.Input(K.int_shape(z)[1:])\n",
        "\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]),\n",
        "                 activation='relu')(decoder_input)\n",
        "\n",
        "# reshape\n",
        "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
        "\n",
        "# use Conv2DTranspose to reverse the conv layers from the encoder\n",
        "x = layers.Conv2DTranspose(32, 3,\n",
        "                           padding='same', \n",
        "                           activation='relu',\n",
        "                           strides=(3, 3))(x)\n",
        "x = layers.Conv2D(1, 3,\n",
        "                  padding='same', \n",
        "                  activation='sigmoid')(x)\n",
        "\n",
        "# decoder model statement\n",
        "decoder = Model(decoder_input, x)\n",
        "\n",
        "# apply the decoder to the sample from the latent distribution\n",
        "z_decoded = decoder(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "e33j6PNAl3UN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# construct a custom layer to calculate the loss\n",
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "\n",
        "    def vae_loss(self, x, z_decoded):\n",
        "        x = K.flatten(x)\n",
        "        z_decoded = K.flatten(z_decoded)\n",
        "        # Reconstruction loss\n",
        "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "        # KL divergence\n",
        "        kl_loss = -5e-4 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "\n",
        "    # adds the custom loss to the class\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        z_decoded = inputs[1]\n",
        "        loss = self.vae_loss(x, z_decoded)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        return x\n",
        "\n",
        "# apply the custom loss to the input images and the decoded latent distribution sample\n",
        "y = CustomVariationalLayer()([input_img, z_decoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e85eee9c-6c5c-4b5d-ef51-2fbbaec11062",
        "id": "mdkus7tvl31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "cell_type": "code",
      "source": [
        "# VAE model statement\n",
        "vae = Model(input_img, y)\n",
        "vae.compile(optimizer='rmsprop', loss=None)\n",
        "vae.summary()"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_20 (InputLayer)           (None, 111, 111, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 111, 111, 32) 320         input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 37, 37, 64)   18496       conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 37, 37, 64)   36928       conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 37, 37, 64)   36928       conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 87616)        0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 32)           2803744     flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 7)            231         dense_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 7)            231         dense_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 7)            0           dense_41[0][0]                   \n",
            "                                                                 dense_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_38 (Model)                (None, 111, 111, 1)  719681      lambda_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_11 (Cu [(None, 111, 111, 1) 0           input_20[0][0]                   \n",
            "                                                                 model_38[1][0]                   \n",
            "==================================================================================================\n",
            "Total params: 3,616,559\n",
            "Trainable params: 3,616,559\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4a759204-abf5-42ab-e2e5-783aeb42571b",
        "id": "LJF5-q-Ol4Vp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "cell_type": "code",
      "source": [
        "corr_reshape = [np.reshape(c,(111,111,1)) for c in corr_org]\n",
        "vae.fit(x=np.array(corr_reshape), y=None,\n",
        "        shuffle=True,\n",
        "        epochs=100,\n",
        "        batch_size=8)\n"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "184/184 [==============================] - 3s 15ms/step - loss: 2338326850693.7549\n",
            "Epoch 2/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.2159\n",
            "Epoch 3/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.3172\n",
            "Epoch 4/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.3927\n",
            "Epoch 5/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.4338\n",
            "Epoch 6/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.4678\n",
            "Epoch 7/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.4826\n",
            "Epoch 8/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.4916\n",
            "Epoch 9/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.4967\n",
            "Epoch 10/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5046\n",
            "Epoch 11/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5037\n",
            "Epoch 12/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5093\n",
            "Epoch 13/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5096\n",
            "Epoch 14/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5133\n",
            "Epoch 15/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5148\n",
            "Epoch 16/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5150\n",
            "Epoch 17/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5171\n",
            "Epoch 18/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5195\n",
            "Epoch 19/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5196\n",
            "Epoch 20/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5217\n",
            "Epoch 21/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5224\n",
            "Epoch 22/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5254\n",
            "Epoch 23/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5238\n",
            "Epoch 24/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5281\n",
            "Epoch 25/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5280\n",
            "Epoch 26/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5311\n",
            "Epoch 27/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5301\n",
            "Epoch 28/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5306\n",
            "Epoch 29/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5317\n",
            "Epoch 30/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5299\n",
            "Epoch 31/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5211\n",
            "Epoch 32/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5280\n",
            "Epoch 33/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5346\n",
            "Epoch 34/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5342\n",
            "Epoch 35/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5340\n",
            "Epoch 36/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5431\n",
            "Epoch 37/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5394\n",
            "Epoch 38/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5436\n",
            "Epoch 39/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5448\n",
            "Epoch 40/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5462\n",
            "Epoch 41/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5473\n",
            "Epoch 42/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5493\n",
            "Epoch 43/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5507\n",
            "Epoch 44/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5535\n",
            "Epoch 45/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5545\n",
            "Epoch 46/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5548\n",
            "Epoch 47/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5584\n",
            "Epoch 48/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5587\n",
            "Epoch 49/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5609\n",
            "Epoch 50/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5639\n",
            "Epoch 51/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5660\n",
            "Epoch 52/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5670\n",
            "Epoch 53/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5679\n",
            "Epoch 54/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5711\n",
            "Epoch 55/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5726\n",
            "Epoch 56/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5737\n",
            "Epoch 57/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5760\n",
            "Epoch 58/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5772\n",
            "Epoch 59/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5789\n",
            "Epoch 60/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5793\n",
            "Epoch 61/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5808\n",
            "Epoch 62/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5828\n",
            "Epoch 63/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5839\n",
            "Epoch 64/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5848\n",
            "Epoch 65/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5858\n",
            "Epoch 66/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5875\n",
            "Epoch 67/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5878\n",
            "Epoch 68/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5893\n",
            "Epoch 69/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5899\n",
            "Epoch 70/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5914\n",
            "Epoch 71/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5932\n",
            "Epoch 72/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5936\n",
            "Epoch 73/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5947\n",
            "Epoch 74/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5955\n",
            "Epoch 75/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5976\n",
            "Epoch 76/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5983\n",
            "Epoch 77/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.5990\n",
            "Epoch 78/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6002\n",
            "Epoch 79/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6015\n",
            "Epoch 80/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6030\n",
            "Epoch 81/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6036\n",
            "Epoch 82/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6049\n",
            "Epoch 83/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6059\n",
            "Epoch 84/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6070\n",
            "Epoch 85/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6088\n",
            "Epoch 86/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6084\n",
            "Epoch 87/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6104\n",
            "Epoch 88/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6111\n",
            "Epoch 89/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6115\n",
            "Epoch 90/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6135\n",
            "Epoch 91/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6144\n",
            "Epoch 92/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6147\n",
            "Epoch 93/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6160\n",
            "Epoch 94/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6177\n",
            "Epoch 95/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6171\n",
            "Epoch 96/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6189\n",
            "Epoch 97/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6198\n",
            "Epoch 98/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6207\n",
            "Epoch 99/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6222\n",
            "Epoch 100/100\n",
            "184/184 [==============================] - 1s 4ms/step - loss: -0.6215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b24bb0c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8ebfa6df-ae42-4e84-cd11-d8b6ed05f6d0",
        "id": "nLkRwnnel5h5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "encoder = Model(input_img, z_mu)\n",
        "vae_reg = encoder.predict(np.array(corr_reshape), batch_size=batch_size)\n",
        "'''print(x_valid_noTest_encoded[0])\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "plt.figure(figsize=(10, 10))\n",
        "ax.scatter3D(x_valid_noTest_encoded[:, 0], x_valid_noTest_encoded[:, 1],  x_valid_noTest_encoded[:, 2])\n",
        "plt.show()'''\n",
        "#Visualize latent space"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"print(x_valid_noTest_encoded[0])\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfig = plt.figure()\\nax = plt.axes(projection='3d')\\nplt.figure(figsize=(10, 10))\\nax.scatter3D(x_valid_noTest_encoded[:, 0], x_valid_noTest_encoded[:, 1],  x_valid_noTest_encoded[:, 2])\\nplt.show()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "metadata": {
        "id": "wOOQ1a1ZhYp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ec22ab59-53b8-415f-d70e-33ad1e180797"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import SVR\n",
        "lr = SVC(gamma='auto')\n",
        "#logisticRegr = LogisticRegression()\n",
        "vae_reg = np.array(vae_reg)\n",
        "#print(vae_reg[np.where(np.isnan(vae_reg))])\n",
        "lr.fit(vae_reg, np.array(diagnoses_group))\n",
        "\n",
        "lr.predict(vae_reg)\n",
        "score = lr.score(vae_reg,np.array( diagnoses_group))\n",
        "print(\"For Diagnoses prediction\", score)\n",
        "\n",
        "#lrmt = LogisticRegression(multi_class='multinomial', solver =  'lbfgs')\n",
        "y = np.array(pdd_category)\n",
        "lr.fit(vae_reg,y)\n",
        "lr.predict(vae_reg)\n",
        "score = lr.score(vae_reg,y)\n",
        "print ('PDD Category from DSM IV ', score)\n",
        "\n",
        "#lr = LinearRegression()#LogisticRegression(multi_class='multinomial', solver =  'lbfgs')\n",
        "lr = SVR()\n",
        "y = np.array(adi_r_social)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = vae_reg[np.where(~np.isnan(y) )]\n",
        "y = y[ np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"adi-r-social \", score)\n",
        "\n",
        "y= np.array(adi_r_verbal)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = vae_reg[np.where(~np.isnan(y)  )]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"adi-r-verbal \", score)\n",
        "\n",
        "y= np.array(ados_total)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = vae_reg[np.where(~np.isnan(y))]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"ados total \", score)\n",
        "\n",
        "y= np.array(ados_serverity)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = vae_reg[np.where(~np.isnan(y))]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"ados serverity \", score)\n",
        "\n",
        "y= np.array(ados_socaffect)\n",
        "y[np.where(y == -9.999e+03 )] = float('nan')\n",
        "x = vae_reg[np.where(~np.isnan(y))]\n",
        "y = y[np.where(~np.isnan(y))]\n",
        "lr.fit(x, y)\n",
        "score = lr.score(x,y)\n",
        "print(\"ados social affect \", score)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Diagnoses prediction 0.8804347826086957\n",
            "PDD Category from DSM IV  0.7119565217391305\n",
            "adi-r-social  0.24082670670905074\n",
            "adi-r-verbal  0.245677496541673\n",
            "ados total  0.3118264475434387\n",
            "ados serverity  0.3675975660126283\n",
            "ados social affect  0.22979608027985154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E3lWK5TEtLB-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results with VAE"
      ]
    },
    {
      "metadata": {
        "id": "GM72619Dl3fu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With 7 latent variables: \n",
        "\n",
        "Classification Accuracy\n",
        "* For Diagnoses prediction 0.8804347826086957\n",
        "* PDD Category from DSM IV  0.7119565217391305\n",
        "\n",
        "Correlation from Regression\n",
        "\n",
        "* adi-r-social  0.24082670670905074\n",
        "* adi-r-verbal  0.245677496541673\n",
        "* ados total  0.3118264475434387\n",
        "* ados serverity  0.3675975660126283\n",
        "* ados social affect  0.22979608027985154\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "C6ZT-b0-qYyJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With 20 Latent Variables:\n",
        "\n",
        "* For Diagnoses prediction 0.7934782608695652 (Classification Accuracy)\n",
        "* PDD Category prediction from DSM IV  0.6793478260869565 (Classification Accuracy)\n",
        "\n",
        "These are correlation\n",
        "* adi-r-social  0.20724689666450424\n",
        "* adi-r-verbal  0.1942414422201446\n",
        "* ados total  0.1870398614136629\n",
        "* ados serverity  0.3316804257464101\n",
        "* ados social affect  0.21155238252912467"
      ]
    }
  ]
}